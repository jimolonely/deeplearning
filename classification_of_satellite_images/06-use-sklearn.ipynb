{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.feature_selection as fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  997.9039917    637.5949707    658.66802979 ..., -2203.02001953\n  -1180.18994141   433.90600586]\n [  914.19799805   634.23999023   593.70501709 ..., -2250.         -1360.56005859\n    524.07501221]\n [ 3800.81005859  1671.33996582  1206.88000488 ...,  2762.57006836\n    150.93099976  3800.81005859]\n ..., \n [ 5833.75976562  3465.73999023  1283.31994629 ...,  3759.70996094\n   3267.16992188   388.3460083 ]\n [ 3079.31005859  2435.30004883  1444.40002441 ...,  1880.58996582\n   1614.83996582  1518.97998047]\n [ 7352.56982422  6941.18994141  1667.86999512 ...,  5983.12988281\n   1249.70996094  2424.22998047]]\n[0 0 0 ..., 5 5 5]\n[[ 2750.11010742  1361.89001465  -247.50799561 ...,   -81.54180145\n   1146.26000977 -1566.48999023]\n [ 2646.25        1760.84997559   481.1000061  ...,   668.75        1519.73999023\n   -568.97302246]\n [ 3509.62011719  3509.62011719  -241.32000732 ...,  1132.90002441\n    594.059021    -993.65802002]\n ..., \n [  987.46099854 -2364.60009766  -155.59199524 ..., -4259.29980469\n    412.11499023 -1170.75      ]\n [  973.95300293 -3004.62988281 -1217.11999512 ..., -5574.50976562\n    298.73901367   460.41900635]\n [  516.42700195 -2975.10009766 -1129.79003906 ..., -5453.33007812\n    307.49499512   417.12399292]]\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 4 1 1 1 1 4 1 1 1 1 1 1 3 1 1 1 1 1\n 1 1 1 1 4 2 1 4 1 0 0 1 1 1 2 1 0 0 1 1 2 1 1 1 1 1 1 1 1 4 1 1 1 4 2 4 0\n 0 0 0 0 1 5 4 5 5 5 5 5 1 5 5 5 5 5 5 4 4 3 5 5 5 5 1 4 5 1 3 5 5 5 4 5 4\n 4 1 5 5 4 3 4 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 1 2 1 3 3 2 5 4 3 3 2 2 2\n 2 2 2 2 2 3 3 3 2 3 3 3 3 3 3 3 3 3 5 5 5 3 3 3 3 5 2 2 2 5 3 3 2 2 3 3 2\n 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 4 5 5 5 1 4 3 3 3 3 5 4 3 5 4 5\n 3 5 4 5 3 3 3 5 2 2 2 2 2 1 4 4 1 1 1 1 1 1 1 1 1 4 4 1 1 1 1 1 1 4 1 4 4\n 4 1 1 1 4 4 4 4 4 1 1 1 1 1 1 1 5 5 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_FILE = \"train_data.csv\"\n",
    "TEST_DATA_FILE = \"test_data.csv\"\n",
    "\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=TRAIN_DATA_FILE,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32,\n",
    "    target_column=0\n",
    ")\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=TEST_DATA_FILE,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32,\n",
    "    target_column=0\n",
    ")\n",
    "# print(training_set)\n",
    "X, y = training_set.data, training_set.target\n",
    "print(X)\n",
    "print(y)\n",
    "X_test, y_test = test_set.data, test_set.target\n",
    "print(X_test)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10545, 28)\n(10545,)\n"
     ]
    }
   ],
   "source": [
    "# 重复度检测\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))  # 去除重复度超过80%的值\n",
    "sel.fit_transform(X,y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10545, 28)\n(10545, 20)\n"
     ]
    }
   ],
   "source": [
    "# 单变量因素\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "\n",
    "percentile = SelectPercentile(score_func=fs.f_classif, percentile=100)\n",
    "X_new1 = percentile.fit_transform(X, y) # 保留50%的特征\n",
    "k_best = SelectKBest(score_func=fs.f_classif, k=20)\n",
    "X_new2 = k_best.fit_transform(X, y)\n",
    "print(X_new1.shape)\n",
    "print(X_new2.shape)\n",
    "\n",
    "percentile_index = percentile.get_support()\n",
    "k_best_index = k_best.get_support()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10545, 28)\n"
     ]
    }
   ],
   "source": [
    "# 使用模型选择\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "lsvc = LinearSVC(C=0.001, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new3 = model.transform(X)\n",
    "print(X_new3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14159599  0.05793408  0.04608993  0.03809199  0.03637399  0.01931587\n  0.04076579  0.02698541  0.0301383   0.02475596  0.05564788  0.01581794\n  0.02571292  0.01788414  0.0356699   0.02358209  0.03453728  0.02494789\n  0.0378345   0.02198905  0.03628434  0.03346055  0.02329732  0.01854243\n  0.02141414  0.05936967  0.0204838   0.03147685]\n(10545, 10)\n[ True  True  True  True  True False  True False False False  True False\n False False False False False False  True False  True False False False\n False  True False False]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "print(clf.feature_importances_) \n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new4 = model.transform(X)\n",
    "print(X_new4.shape)\n",
    "print(model.get_support()) # 取得被选出的列,就是为True的那些\n",
    "\n",
    "tree_model_index = model.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算哪些特征被选中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  997.9039917    637.5949707    658.66802979 -1882.0300293  -1924.35998535\n   997.9039917  -1739.98999023   630.0869751  -1628.23999023 -1325.64001465\n  -944.08398438   277.10699463  -206.79899597   536.440979     749.34802246\n  -482.99301147   492.00100708   655.77001953  -921.19299316 -1043.16003418\n -1942.48999023   267.13800049   366.60800171   452.23800659   211.32800293\n -2203.02001953 -1180.18994141   433.90600586]\n[  997.9039917    637.5949707    658.66802979 -1882.0300293  -1924.35998535\n -1739.98999023  -944.08398438  -921.19299316 -1942.48999023 -2203.02001953]\n[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n"
     ]
    }
   ],
   "source": [
    "# 无奈之举\n",
    "def get_select_features_index2(X, X_new):\n",
    "    '''X:传入第一行就行了'''\n",
    "    index = []\n",
    "    item = set()\n",
    "    print(X)\n",
    "    print(X_new)\n",
    "    for x in X_new:\n",
    "        for i, y in enumerate(X):\n",
    "            if x == y and y not in item:\n",
    "                item.add(y)\n",
    "                index.append(i)\n",
    "    return index\n",
    "# test\n",
    "index = get_select_features_index2(X[0], X_new4[0])\n",
    "print(index)\n",
    "# 可看到有相同的列\n",
    "\n",
    "def get_select_features_index(bool_arr):\n",
    "    '''传入model.get_support()'''\n",
    "    index = [i for i, b in enumerate(bool_arr) if b == True]\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取其他选出的列\n",
    "\n",
    "def get_X_new(X, index):\n",
    "    '''传入被选出的列的下标列表,返回新的数据集'''\n",
    "    mask = [False] * X.shape[1]\n",
    "    for i in index:\n",
    "        mask[i] = True\n",
    "    return X[:, mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通用测试函数\n",
    "\n",
    "def general_test(feature_index, X_new, classifier):\n",
    "    features_index = get_select_features_index(feature_index)\n",
    "    print(features_index)\n",
    "    \n",
    "    X_test_r = get_X_new(X_test, features_index)\n",
    "    print(X_test_r.shape)\n",
    "\n",
    "    cls = classifier()\n",
    "    y_pred = cls.fit(X_new, y).predict(X_test_r)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n0.59\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n0.686666666667\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n0.633333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "general_test(tree_model_index,X_new4,GaussianNB)\n",
    "general_test(percentile_index,X_new1,GaussianNB)\n",
    "general_test(k_best_index,X_new2,GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.326666666667\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.416666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "general_test(tree_model_index,X_new4,LinearSVC)\n",
    "general_test(percentile_index,X_new1,LinearSVC)\n",
    "general_test(k_best_index,X_new2,LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "general_test(tree_model_index,X_new4,SVC)\n",
    "general_test(percentile_index,X_new1,SVC)\n",
    "general_test(k_best_index,X_new2,SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.466666666667\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.526666666667\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.566666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "general_test(tree_model_index,X_new4,AdaBoostClassifier)\n",
    "general_test(percentile_index,X_new1,AdaBoostClassifier)\n",
    "general_test(k_best_index,X_new2,AdaBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.583333333333\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543333333333\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "general_test(tree_model_index,X_new4,BaggingClassifier)\n",
    "general_test(percentile_index,X_new1,BaggingClassifier)\n",
    "general_test(k_best_index,X_new2,BaggingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n0.593333333333\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.643333333333\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n0.623333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "general_test(tree_model_index,X_new4,ExtraTreesClassifier)\n",
    "general_test(percentile_index,X_new1,ExtraTreesClassifier)\n",
    "general_test(k_best_index,X_new2,ExtraTreesClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.636666666667\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.593333333333\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.593333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "general_test(tree_model_index,X_new4,GradientBoostingClassifier)\n",
    "general_test(percentile_index,X_new1,GradientBoostingClassifier)\n",
    "general_test(k_best_index,X_new2,GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.613333333333\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.606666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "general_test(tree_model_index,X_new4,RandomForestClassifier)\n",
    "general_test(percentile_index,X_new1,RandomForestClassifier)\n",
    "general_test(k_best_index,X_new2,RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.483333333333\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "general_test(tree_model_index,X_new4,LogisticRegression)\n",
    "general_test(percentile_index,X_new1,LogisticRegression)\n",
    "general_test(k_best_index,X_new2,LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.513333333333\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "general_test(tree_model_index,X_new4,LogisticRegressionCV)\n",
    "general_test(percentile_index,X_new1,LogisticRegressionCV)\n",
    "general_test(k_best_index,X_new2,LogisticRegressionCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n0.17\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n0.486666666667\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "general_test(tree_model_index,X_new4,PassiveAggressiveClassifier)\n",
    "general_test(percentile_index,X_new1,PassiveAggressiveClassifier)\n",
    "general_test(k_best_index,X_new2,PassiveAggressiveClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n0.41\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n0.436666666667\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n0.443333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "general_test(tree_model_index,X_new4,RidgeClassifier)\n",
    "general_test(percentile_index,X_new1,RidgeClassifier)\n",
    "general_test(k_best_index,X_new2,RidgeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n0.41\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n0.436666666667\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.443333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "general_test(tree_model_index,X_new4,RidgeClassifierCV)\n",
    "general_test(percentile_index,X_new1,RidgeClassifierCV)\n",
    "general_test(k_best_index,X_new2,RidgeClassifierCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 6, 10, 18, 20, 25]\n(300, 10)\n0.346666666667\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n(300, 28)\n0.473333333333\n[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 14, 17, 18, 19, 20, 21, 23, 24, 25, 26]\n(300, 20)\n0.383333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "general_test(tree_model_index,X_new4,SGDClassifier)\n",
    "general_test(percentile_index,X_new1,SGDClassifier)\n",
    "general_test(k_best_index,X_new2,SGDClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通用测试函数--基于神经网络\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def general_test_nn(feature_index, X_new, hidden_layer, activation='relu', alpha=0.0001, solver='adam',max_iter=1000):\n",
    "    features_index = get_select_features_index(feature_index)\n",
    "    # print(features_index)\n",
    "\n",
    "    X_test_r = get_X_new(X_test, features_index)\n",
    "    # print(X_test_r.shape)\n",
    "\n",
    "    cls = MLPClassifier(hidden_layer_sizes=hidden_layer, activation=activation, solver=solver, alpha=alpha)\n",
    "    y_pred = cls.fit(X_new, y).predict(X_test_r)\n",
    "    print(y_pred)\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(acc)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 3 3 5 1 1 1 1 5 1 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 5 1 1 1 5 1 1 1 1 1 1 1 2 1 1 1 1 5 1 1 1 3 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 3 1 1 1 1 1 1 5 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 5 5 5 5 5 5 3 5 5 5 5 5 5 5 5 5\n 5 5 5 5]\n0.263333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 4 4 4 3 3 4 4 3 3 4 3 4 4 4 3 4 3\n 3 3 4 4]\n0.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 2 2 1 5 2 2 1 5 1 1 3 3 3 2 1\n 2 2 3 5]\n0.26\nmax is: 0.263333333333\n"
     ]
    }
   ],
   "source": [
    "# general_test_nn(percentile_index, X_new1, solver='lbfgs', alpha=1e-5, hidden_layer=(30, 100, 6))\n",
    "# general_test_nn(percentile_index, X_new1, solver='lbfgs', alpha=1e-5, hidden_layer=(30, 100, 6))\n",
    "# general_test_nn(percentile_index, X_new1, solver='lbfgs', alpha=1e-5, hidden_layer=(30, 100, 6))\n",
    "\n",
    "# general_test_nn(k_best_index, X_new2, solver='lbfgs', alpha=1e-5, hidden_layer=(30, 50, 6))\n",
    "# general_test_nn(k_best_index, X_new2, solver='lbfgs', alpha=1e-5, hidden_layer=(30, 40, 6))\n",
    "# general_test_nn(k_best_index, X_new2, solver='lbfgs', alpha=1e-5, hidden_layer=(30, 60, 6))\n",
    "\n",
    "max = 0\n",
    "for i in range(3):\n",
    "    cc = general_test_nn(k_best_index, X_new2, solver='lbfgs', alpha=1e-5, hidden_layer=(32,16, 32),\n",
    "                         max_iter=1000)\n",
    "    max = cc if max < cc else max\n",
    "print('max is:', max)\n",
    "\n",
    "# general_test(percentile_index, X_new1, (5,5))\n",
    "# general_test(k_best_index, X_new2, MLPClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
